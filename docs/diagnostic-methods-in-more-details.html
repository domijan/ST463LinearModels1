<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Diagnostic methods (in more details) | Linear Models Lecture Notes</title>
<meta name="author" content="Katarina Domijan">
<meta name="description" content="6.1 Model assumptions The assumptions can be stated in terms of the error vector: \(\mathbb{E}(\boldsymbol{\epsilon}) = \mathbf{0}\) \(\mbox{Var}(\boldsymbol{\epsilon}) = \sigma^2\mathbf{I}_n\)...">
<meta name="generator" content="bookdown 0.46 with bs4_book()">
<meta property="og:title" content="Chapter 6 Diagnostic methods (in more details) | Linear Models Lecture Notes">
<meta property="og:type" content="book">
<meta property="og:description" content="6.1 Model assumptions The assumptions can be stated in terms of the error vector: \(\mathbb{E}(\boldsymbol{\epsilon}) = \mathbf{0}\) \(\mbox{Var}(\boldsymbol{\epsilon}) = \sigma^2\mathbf{I}_n\)...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Diagnostic methods (in more details) | Linear Models Lecture Notes">
<meta name="twitter:description" content="6.1 Model assumptions The assumptions can be stated in terms of the error vector: \(\mathbb{E}(\boldsymbol{\epsilon}) = \mathbf{0}\) \(\mbox{Var}(\boldsymbol{\epsilon}) = \sigma^2\mathbf{I}_n\)...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Linear Models Lecture Notes</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Module Preliminaries</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> Introduction</a></li>
<li><a class="" href="SLR.html"><span class="header-section-number">3</span> Simple Linear regression</a></li>
<li><a class="" href="multiple-regression.html"><span class="header-section-number">4</span> Multiple regression</a></li>
<li><a class="" href="model-comparisons-and-testing-for-lack-of-fit.html"><span class="header-section-number">5</span> Model comparisons and testing for lack of fit</a></li>
<li><a class="active" href="diagnostic-methods-in-more-details.html"><span class="header-section-number">6</span> Diagnostic methods (in more details)</a></li>
<li><a class="" href="special-cases-of-multiple-regression.html"><span class="header-section-number">7</span> Special cases of multiple regression</a></li>
<li><a class="" href="about.html"><span class="header-section-number">8</span> About</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="diagnostic-methods-in-more-details" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Diagnostic methods (in more details)<a class="anchor" aria-label="anchor" href="#diagnostic-methods-in-more-details"><i class="fas fa-link"></i></a>
</h1>
<div id="model-assumptions" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Model assumptions<a class="anchor" aria-label="anchor" href="#model-assumptions"><i class="fas fa-link"></i></a>
</h2>
<p>The assumptions can be stated in terms of the error vector:</p>
<ul>
<li><span class="math inline">\(\mathbb{E}(\boldsymbol{\epsilon}) = \mathbf{0}\)</span></li>
<li><span class="math inline">\(\mbox{Var}(\boldsymbol{\epsilon}) = \sigma^2\mathbf{I}_n\)</span></li>
<li><span class="math inline">\(\boldsymbol{\epsilon} \sim N(\mathbf{0}, \sigma^2\mathbf{I}_n)\)</span></li>
</ul>
<p>Since we do not observe <span class="math inline">\(\boldsymbol{\epsilon}\)</span> we cannot check assumptions directly. Instead we observe residuals <span class="math inline">\(\mathbf{e}\)</span>.</p>
</div>
<div id="residuals-1" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Residuals<a class="anchor" aria-label="anchor" href="#residuals-1"><i class="fas fa-link"></i></a>
</h2>
<p>Residuals are the key to assessing model problems.</p>
<p><span class="math display">\[\mathbf{e} = \mathbf{Y} - \mathbf{\hat{Y}} = \mathbf{Y} - \mathbf{H}\mathbf{Y} = (\mathbf{I} - \mathbf{H})\mathbf{Y} \]</span></p>
<p>How do <span class="math inline">\(\boldsymbol{\epsilon}\)</span> and <span class="math inline">\(\mathbf{e}\)</span> differ?</p>
<p>If the model is correct,</p>
<p><span class="math inline">\(\mathbb{E}(\mathbf{e}) = \mathbb{E}(\mathbf{Y}) - \mathbb{E}(\mathbf{\hat{Y}})= \mathbf{0}\)</span> (the same)</p>
<p><span class="math inline">\(\mbox{Var}(\mathbf{e})  = (\mathbf{I} - \mathbf{H})\sigma^2\)</span> (different).</p>
<p>Like errors, residuals have mean 0, but Var(<span class="math inline">\(e_i) = (1-h_{ii})\sigma^2\)</span> so their variance is not quite constant (variance is smaller for <span class="math inline">\(h_{ii}\)</span> close to 1).</p>
<p>Note: this results shows that the residuals may have different variances even when <span class="math inline">\(y_i\)</span>s have the same variance (<span class="math inline">\(\sigma^2\)</span>) because the precision of the fitted values depends on the pattern of <span class="math inline">\(X_i\)</span>s.</p>
<p>Cov(<span class="math inline">\(e_i, e_j) = -h_{ii}\sigma^2\)</span>, for <span class="math inline">\(i \neq j\)</span>. So the residuals are correlated, but in practice this correlation is generally not important or visible in residual plots.</p>
<p>We plot:</p>
<ul>
<li>
<span class="math inline">\(e_i\)</span> vs <span class="math inline">\(\hat{y}_i\)</span> (residual vs fit),</li>
<li>
<span class="math inline">\(e_i\)</span> vs <span class="math inline">\(X_{ij}\)</span> (residual vs predictor <span class="math inline">\(j\)</span>).</li>
</ul>
<p>The SLR conclusions are clear cut. In multiple regression deviations from the ideal pattern indicate model problems but precise diagnosis is more difficult.</p>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-117-1.png" width="576" style="display: block; margin: auto;"></div>
<p>Figures above:</p>
<ul>
<li><p>ideal pattern: random scatter of points around 0 line</p></li>
<li><p>non-constant variance, variability of residuals is changing</p></li>
<li><p>curvature suggests that: <span class="math inline">\(\mathbb{E}(e_i) \neq 0\)</span>, thus, <span class="math inline">\(\mathbb{E}(\epsilon_i)\neq 0\)</span></p></li>
<li><p>curvature and non-constant variance</p></li>
</ul>
</div>
<div id="leverage-values" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Leverage values<a class="anchor" aria-label="anchor" href="#leverage-values"><i class="fas fa-link"></i></a>
</h2>
<p><span class="math display">\[\begin{align*}
\mathbf{\hat{Y}}  &amp; = \mathbf{H}\mathbf{Y}\\
\mathbf{H}  &amp; = \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\\
h_{ii}  &amp; = \mathbf{X}_i^T(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}_i\\
\end{align*}\]</span></p>
<p><span class="math inline">\(h_{ii}\)</span> is known as the <strong>leverage</strong> of case <span class="math inline">\(i\)</span>.</p>
<p>where <span class="math inline">\(\mathbf{X}_i\)</span> is row <span class="math inline">\(i\)</span> of <span class="math inline">\(\mathbf{X}\)</span> matrix in a column vector.</p>
<p>In SLR,</p>
<p><span class="math display">\[\begin{align*}
h_{ii}  &amp; = \frac{1}{n} + \frac{(x_i - \bar{x})^2}{S_{xx}}.
\end{align*}\]</span></p>
<p>A similar formula can be derived for multiple regression:</p>
<p><span class="math display">\[h_{ii}   = \frac{1}{n} + (\mathbf{X}_i^* -\mathbf{M})(\mathbf{\tilde{X}}^T\mathbf{\tilde{X}})^{-1}(\mathbf{X}_i^* - \mathbf{M}),\]</span></p>
<p>where</p>
<p><span class="math inline">\(\mathbf{X}_i^*\)</span> is row <span class="math inline">\(i\)</span> of <span class="math inline">\(\mathbf{X}\)</span> matrix without the column of <span class="math inline">\(\mathbf{1}\)</span>s.</p>
<p>i.e.</p>
<p><span class="math inline">\(\mathbf{X}_i =\begin{bmatrix} 1 &amp; \mathbf{X}_i^* \end{bmatrix}\)</span></p>
<p><span class="math inline">\(\mathbf{M}\)</span> is the mean vector</p>
<p><span class="math display">\[\mathbf{M} =\begin{bmatrix} \bar{X}_{.1}\\ \vdots  \\ \bar{X}_{.k} \end{bmatrix}\]</span></p>
<p><span class="math inline">\(\tilde{\mathbf{X}}\)</span> is the matrix of centered <span class="math inline">\(x\)</span> - data values, i.e.</p>
<p><span class="math display">\[\tilde{\mathbf{X}}  =\begin{bmatrix} (X_{11} - \bar{X}_{.1}) &amp; \dots &amp; (X_{1k} - \bar{X}_{.k}) \\ (X_{21} - \bar{X}_{.1})  &amp; \dots &amp; (X_{2k} - \bar{X}_{.k})  \\ \vdots &amp; \vdots &amp;\vdots \\ (X_{n1} - \bar{X}_{.1})  &amp; \dots &amp; (X_{nk} - \bar{X}_{.k})  \end{bmatrix} \]</span></p>
<p><span class="math inline">\(\bar{X}_{.1}, \dots, \bar{X}_{.k}\)</span> are the means of the <span class="math inline">\(k\)</span> predictors.</p>
<p>Therefore <span class="math inline">\(h_{ii}\)</span> measures the `distance’ of case <span class="math inline">\(i\)</span> from the average case <span class="math inline">\(\mathbf{M}\)</span>.</p>
<p>Example <span class="math inline">\(k=2\)</span>: contours of constant <span class="math inline">\(h_{ii}\)</span></p>
<p>All points on an ellipse have the same <span class="math inline">\(h_{ii}\)</span> value.</p>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-118-1.png" width="384" style="display: block; margin: auto;"></div>
<div id="properties-of-h_ii" class="section level3" number="6.3.1">
<h3>
<span class="header-section-number">6.3.1</span> Properties of <span class="math inline">\(h_{ii}\)</span>:<a class="anchor" aria-label="anchor" href="#properties-of-h_ii"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><p><span class="math inline">\(0 \leq h_{ii} \leq 1\)</span> or if the model has an intercept <span class="math inline">\(\frac{1}{n} \leq h_{ii} \leq 1\)</span></p></li>
<li><p><span class="math inline">\(\sum_{i=1}^n h_{ii}  =p\)</span> where <span class="math inline">\(p\)</span> is the number of parameters</p></li>
<li><p><span class="math inline">\(\sum_{i=1}^n h_{ij}  =\sum_{j=1}^n h_{ij}  = 1\)</span>, i.e. row sum = col sum = 1.</p></li>
</ul>
<p>If <span class="math inline">\(h_{ii}\)</span> is large (rule of thumb: large if <span class="math inline">\(\geq 2 \times \mbox{average } h_{ii} = 2p/n\)</span>), then the case may be:</p>
<ul>
<li>a mistake</li>
<li>a high influence case (i.e. has a big impact on results).</li>
</ul>
<p>If <span class="math inline">\(h_{ii}\)</span> is extremely large (i.e. close to 1):</p>
<ul>
<li>
<span class="math inline">\(\hat{y}_i \approx y_i\)</span> so <span class="math inline">\(e_i \approx 0\)</span> and</li>
<li>Var(<span class="math inline">\(\hat{y}_i)= h_{ii}\sigma^2 \approx  \sigma^2 \approx\)</span> Var(<span class="math inline">\(y_i\)</span>).</li>
</ul>
<p>In this case <span class="math inline">\(\mathbb{E}(y_i)\)</span> is imprecisely estimated. In practice, this rarely happens.</p>
</div>
</div>
<div id="standardised-residuals" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> Standardised residuals<a class="anchor" aria-label="anchor" href="#standardised-residuals"><i class="fas fa-link"></i></a>
</h2>
<p>When we compare residuals (<span class="math inline">\(e_i\)</span>) for different observations we should take into account that their variances may differ:</p>
<p><span class="math display">\[\mbox{Var}(e_i) = (1-h_{ii})\sigma^2.\]</span></p>
<p>We can standardise them by dividing by <span class="math inline">\(\sqrt{(1-h_{ii})}\hat{\sigma}\)</span>, where <span class="math inline">\(\hat{\sigma}\)</span> is the estimate based on the SSE. We get <strong>standardised residuals</strong>:</p>
<p><span class="math display">\[r_i=\frac{e_i}{\sqrt{(1-h_{ii})}\hat{\sigma}}.\]</span></p>
<p>Then we have: <span class="math inline">\(\mathbb{E}(r_i) = 0\)</span> and <span class="math inline">\(\mbox{Var}(r_i)\approx 1\)</span> (constant).</p>
<p>Since <span class="math inline">\(r_i\)</span>, unlike <span class="math inline">\(e_i\)</span>, are on a common scale it is easier/fairer to compare them.</p>
<p>Standardised residuals are useful in detecting anomalous observations or outliers.</p>
<p>Note:</p>
<ul>
<li>Cases with <span class="math inline">\(|r_i| \geq 2\)</span> are not well fit.</li>
<li>
<span class="math inline">\(r_i\)</span> are often used in place of <span class="math inline">\(e_i\)</span> in residual plots and normal probability plots.</li>
<li>
<span class="math inline">\(r_i\)</span> (and <span class="math inline">\(e_i\)</span>) are not independent.</li>
</ul>
</div>
<div id="leave-one-out-methods" class="section level2" number="6.5">
<h2>
<span class="header-section-number">6.5</span> Leave-one-out methods<a class="anchor" aria-label="anchor" href="#leave-one-out-methods"><i class="fas fa-link"></i></a>
</h2>
<p>Remember that as <span class="math inline">\(h_{ii}\)</span> approaches 1, the variance of the residual approaches 0, indicating that the fitted value <span class="math inline">\(\hat{y}_i\)</span> is pulled close to the observed value <span class="math inline">\(y_i\)</span>.</p>
<p>So <strong>leverage</strong> <span class="math inline">\(h_{ii}\)</span> is the <strong>potential influence</strong> of the <span class="math inline">\(i^{th}\)</span> observation.</p>
<p>Observations with high leverage need to be inspected carefully as they might have a large influence on the fit.</p>
<p>Note that <strong>potential influence</strong> is not necessarily the same thing as <strong>actual influence</strong>, since it is might be the case that the observation is in line with rest of the data, and fitting the model without this observation would give a prediction close to the observed <span class="math inline">\(y_i\)</span> anyhow.</p>
<p>One way to examine actual influence of case <span class="math inline">\(i\)</span> is to compare the regression results with case <span class="math inline">\(i\)</span> to those without case <span class="math inline">\(i\)</span>.</p>
<p>Denote the fitted values with all cases included as <span class="math inline">\(\hat{y}_1, \hat{y}_2, ..., \hat{y}_n\)</span> as usual.</p>
<p>Denote the fitted values with case <span class="math inline">\(i\)</span> removed as <span class="math inline">\(\hat{y}_{1(i)}, \hat{y}_{2(i)}, ..., \hat{y}_{n(i)}\)</span>, <span class="math inline">\(i = 1,...,n\)</span>.</p>
<p><strong>Cook’s distance</strong> measures the influence of the <span class="math inline">\(i^{th}\)</span> case by:</p>
<p><span class="math display">\[D_i = \sum_{j=1}^n \frac{(\hat{y}_{j}-\hat{y}_{j(i)})^2}{p \hat{\sigma}^2}.\]</span></p>
<p>Note this is proportional to the Euclidean distance (SS) between fitted values obtained by omitting the <span class="math inline">\(i^{th}\)</span> observation <span class="math inline">\(\hat{y}_{j(i)}\)</span> and fitted values based on all the data <span class="math inline">\(\hat{y}_{j}\)</span>.</p>
<p>Typically we examine the case with the largest <span class="math inline">\(D_i\)</span> further or, in the case of large datasets, the few cases with the largest <span class="math inline">\(D_i\)</span> values, as these have the largest influence.</p>
<p>So does the computation of Cook’s distance <span class="math inline">\(D_i\)</span> for all observations require refitting the model <span class="math inline">\(n\)</span> times? This would be computationally expensive!</p>
<p>It turns out that we can rewrite the above formula for <span class="math inline">\(D_i\)</span> as a function of the standardised residual <span class="math inline">\(r_i\)</span> and the leverage <span class="math inline">\(h_{ii}\)</span>. So in the end we only need to fit the model once and then we can compute <span class="math inline">\(D_i\)</span> from the complete data regression results.</p>
<p>Shortcut formula:</p>
<p><span class="math display">\[\hat{y}_{j(i)}=\hat{y}_{j}- \frac{h_{ij}}{1-h_{ii}}e_i.\]</span></p>
<p>Thus:</p>
<p><span class="math display">\[\hat{y}_{j}-\hat{y}_{j(i)}= \frac{h_{ij}}{1-h_{ii}}e_i\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align*}
\sum_j(\hat{y}_{j}-\hat{y}_{j(i)})^2 &amp; = \frac{e_i^2}{(1-h_{ii})^2}\sum_j h_{ij}^2\\
&amp; = \frac{e_i^2 h_{ii}}{(1-h_{ii})^2},\\
\end{align*}\]</span></p>
<p>from the properties of the H matrix (symmetric and idempotent).</p>
<p>Hence:</p>
<p><span class="math display">\[\begin{align*}
D_i&amp; = \frac{e_i^2 h_{ii}}{p \hat{\sigma}^2(1-h_{ii})^2}\\
D_i&amp; =  \frac{r_i^2h_{ii}}{p(1-h_{ii})}.\\
\end{align*}\]</span></p>
<p>In general, high influence or outlier cases have either:</p>
<ul>
<li><p>Big <span class="math inline">\(|r_i|\)</span> and big <span class="math inline">\(h_{ii}\)</span>.</p></li>
<li><p>Big <span class="math inline">\(|r_i|\)</span> and moderate <span class="math inline">\(h_{ii}\)</span>.</p></li>
<li><p>Moderate <span class="math inline">\(|r_i|\)</span> and big <span class="math inline">\(h_{ii}\)</span>.</p></li>
</ul>
</div>
<div id="other-influence-measures" class="section level2" number="6.6">
<h2>
<span class="header-section-number">6.6</span> Other influence measures<a class="anchor" aria-label="anchor" href="#other-influence-measures"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>
<span class="math inline">\(\hat{\beta_j}-\hat{\beta}_{j(i)}\)</span> (the effect of leaving case <span class="math inline">\(i\)</span> out)</li>
<li>
<span class="math inline">\(\hat{\sigma}_{(i)}\)</span> (estimate of <span class="math inline">\(\sigma\)</span> with case <span class="math inline">\(i\)</span> omitted). Used in: “studentised residual” = <span class="math inline">\(\frac{\hat{\epsilon_i}}{\sqrt{1-h_{ii}}\hat{\sigma}_{(i)}}\)</span>
</li>
</ul>
</div>
<div id="testing-outliers" class="section level2" number="6.7">
<h2>
<span class="header-section-number">6.7</span> Testing outliers<a class="anchor" aria-label="anchor" href="#testing-outliers"><i class="fas fa-link"></i></a>
</h2>
<p>If an individual case is suspected of being an outlier a formal hypothesis test can be performed to verify.
Details of the test are in Chapter 9 of <span class="citation">Weisberg (<a href="references.html#ref-weisberg2005applied">2005</a>)</span>.</p>
<p>For more on leverages and influence see Chapter 2 of <span class="citation">Rodrı́guez (<a href="references.html#ref-Rodriguez2007">2007</a>)</span>. For a very detailed exposition on linear model diagnostics see Chapter 11 and 12 of <span class="citation">Fox (<a href="references.html#ref-fox2016applied">2016</a>)</span>.</p>
</div>
<div id="diagnostics-examples-two-case-studies" class="section level2" number="6.8">
<h2>
<span class="header-section-number">6.8</span> Diagnostics examples (two case studies)<a class="anchor" aria-label="anchor" href="#diagnostics-examples-two-case-studies"><i class="fas fa-link"></i></a>
</h2>
<div id="example-1-brain-size-versus-body-gestation-period-and-litter" class="section level3" number="6.8.1">
<h3>
<span class="header-section-number">6.8.1</span> Example 1: Brain size versus body gestation period and litter<a class="anchor" aria-label="anchor" href="#example-1-brain-size-versus-body-gestation-period-and-litter"><i class="fas fa-link"></i></a>
</h3>
<p>Example from <span class="citation">Ramsey and Schafer (<a href="references.html#ref-ramsey2002statistical">2002</a>)</span> (case0902 in library(Sleuth3)).</p>
<p>It is known that body size of mammals is a good predictor of brain size but it was of interest to know if gestation period and litter size were also good predictors. This data contains average values of brain weight, body weight, gestation length and litter size in 96 species of mammals.</p>
<div class="sourceCode" id="cb189"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">brain.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"data/Species_brain.csv"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-120-1.png" width="576" style="display: block; margin: auto;"></div>
<p>Does the model fit well? Outliers, nonlinearity? NOTE: in MTB you can use brushing (set species as ID variables) and link the graphs to explore the data.</p>
<div class="sourceCode" id="cb190"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#library(car)</span></span>
<span><span class="co">#library(MASS)</span></span>
<span><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">BRAIN</span> <span class="op">~</span> <span class="va">BODY</span> <span class="op">+</span> <span class="va">GESTATION</span> <span class="op">+</span> <span class="va">LITTER</span>, <span class="va">brain.data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = BRAIN ~ BODY + GESTATION + LITTER, data = brain.data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1026.68   -62.08    17.29    51.73   988.76 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -225.29213   83.05875  -2.712  0.00797 ** 
## BODY           0.98588    0.09428  10.457  &lt; 2e-16 ***
## GESTATION      1.80874    0.35445   5.103 1.79e-06 ***
## LITTER        27.64864   17.41429   1.588  0.11579    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 224.6 on 92 degrees of freedom
## Multiple R-squared:   0.81,  Adjusted R-squared:  0.8038 
## F-statistic: 130.7 on 3 and 92 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb192"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># anova(fit1)</span></span></code></pre></div>
<p>Clearly the model is defective.</p>
<ul>
<li><p>The normal probability plot shows that the residuals come from a heavy tailed distribution.</p></li>
<li><p>The residual vs fit plot shows a linear pattern for the majority of data and a few outliers. Most of the pattern is hidden because the data is clumped together. We also observe unequal variance.</p></li>
</ul>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-122-1.png" width="576" style="display: block; margin: auto;"></div>
<p>African elephant, Hippopotamus, Dolphin, Human have large standardised residuals.</p>
<p>African elephant, Hippopotamus and Dolphin, have large influence.</p>
<div class="sourceCode" id="cb193"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">|&gt;</span> <span class="fu">augment</span><span class="op">(</span><span class="va">brain.data</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="va">.cooksd</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 6 × 11
##   SPECIES      BRAIN  BODY GESTATION LITTER .fitted .resid   .hat .sigma .cooksd
##   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 African ele…  4480  2800       655      1   3748.   732. 0.719    173. 24.3   
## 2 Hippopotamus   590  1400       240      1   1617. -1027. 0.251    188.  2.34  
## 3 Dolphin       1600   160       360      1    611.   989. 0.0791   198.  0.452 
## 4 Human being   1300    65       270      1    355.   945. 0.0352   202.  0.168 
## 5 Tapir          250   230       390      1    735.  -485. 0.0945   219.  0.134 
## 6 Domestic pig   180   190       115      8    391.  -211. 0.170    224.  0.0548
## # ℹ 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb195"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">|&gt;</span> <span class="fu">augment</span><span class="op">(</span><span class="va">brain.data</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="va">.hat</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 6 × 11
##   SPECIES    BRAIN   BODY GESTATION LITTER .fitted  .resid   .hat .sigma .cooksd
##   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;     &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 African… 4480    2.8e+3       655    1    3748.    732.  0.719    173. 2.43e+1
## 2 Hippopo…  590    1.4e+3       240    1    1617.  -1027.  0.251    188. 2.34e+0
## 3 Domesti…  180    1.9e+2       115    8     391.   -211.  0.170    224. 5.48e-2
## 4 Rat II      2.38 3.4e-1        21    8      34.2   -31.8 0.134    226. 8.98e-4
## 5 Rat I       0.72 5  e-2        23    7.3    18.2   -17.5 0.102    226. 1.92e-4
## 6 Tapir     250    2.3e+2       390    1     735.   -485.  0.0945   219. 1.34e-1
## # ℹ 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb197"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">|&gt;</span> <span class="fu">augment</span><span class="op">(</span><span class="va">brain.data</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">.std.resid</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 5 × 11
##   SPECIES      BRAIN  BODY GESTATION LITTER .fitted .resid   .hat .sigma .cooksd
##   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 African ele…  4480  2800       655      1   3748.   732. 0.719    173.  24.3  
## 2 Hippopotamus   590  1400       240      1   1617. -1027. 0.251    188.   2.34 
## 3 Dolphin       1600   160       360      1    611.   989. 0.0791   198.   0.452
## 4 Human being   1300    65       270      1    355.   945. 0.0352   202.   0.168
## 5 Tapir          250   230       390      1    735.  -485. 0.0945   219.   0.134
## # ℹ 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<!-- ```{r } -->
<!-- #################### -->
<!-- # influence measures -->
<!-- #################### -->
<!-- inflm.SR <- influence.measures(fit1) -->
<!-- int <- which(apply(inflm.SR$is.inf, 1, any)) -->
<!-- cbind(brain.data[int ,], -->
<!--       influence(fit1)$hat[int],# large leverage -->
<!--       stdres(fit1)[int],# large std residual -->
<!--       abs(D)[int]) # large Cook's D -->
<!-- ``` -->
<!-- % #################### -->
<!-- % # large leverage -->
<!-- % #################### -->
<!-- %  -->
<p><!-- % head(brain.data[sort(influence(fit1)$hat, decreasing = TRUE, index.return = TRUE)$ix, 1]) -->
<!-- %  -->
<!-- % #################### -->
<!-- % # large std residual -->
<!-- % #################### -->
<!-- %  -->
<!-- % head(brain.data[sort(abs(stdres(fit1)), decreasing = TRUE, index.return = TRUE)$ix, ]) -->
<!-- %  -->
<!-- %  -->
<!-- % ################ -->
<!-- % # large Cook's D -->
<!-- % ################ -->
<!-- %  -->
<!-- % head(brain.data[sort(abs(D), decreasing = TRUE, index.return = TRUE)$ix, 1]) --></p>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-124-1.png" width="576" style="display: block; margin: auto;"></div>
<p>Added-variable plots can be used for detecting influential data.</p>
<p>For example, AVP for <strong>body</strong>:</p>
<ul>
<li><p>Hippo and African elephant have a large body given the other variables (litter and gestation).</p></li>
<li><p>Humans, dolphins and African elephant have a large brain for their litter and gestation.</p></li>
<li><p>Together Humans, dolphins and hippos reduce the body slope, African elephant, while a high-leverage point, is more in line with the rest of the data.</p></li>
</ul>
<!-- % nonlinearity --><p><!-- %```{r fig.width=6,fig.height=6.5, results='hide',echo=FALSE, fig.align='center'} -->
<!-- % # component + residual plot -->
<!-- % crPlots(fit1) -->
<!-- %  ej <- coefficients(fit1)[2] * BODY + resid(fit1) -->
<!-- % plot(BODY, ej) -->
<!-- %``` -->
<!-- %  -->
<!-- %  --></p>
<p>The raw data have a lot of skeweness. This naturally generates a lot of outliers and obscures patterns in the data.</p>
<p>Transform the data by taking the logs to improve the model and fit.</p>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-125-1.png" width="576" style="display: block; margin: auto;"></div>
<p>The skeweness is gone. The plot of log(brain) vs log(body) shows a strong linear pattern - not apparent with the untransformed variables. Therefore the log transformation of these two variables seems appropriate. The other variables are also less skewed than before.</p>
<div class="sourceCode" id="cb199"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">BRAIN</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">BODY</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">GESTATION</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">LITTER</span><span class="op">)</span>, <span class="va">brain.data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(BRAIN) ~ log(BODY) + log(GESTATION) + log(LITTER), 
##     data = brain.data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.95415 -0.29639 -0.03105  0.28111  1.57491 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     0.85482    0.66167   1.292  0.19962    
## log(BODY)       0.57507    0.03259  17.647  &lt; 2e-16 ***
## log(GESTATION)  0.41794    0.14078   2.969  0.00381 ** 
## log(LITTER)    -0.31007    0.11593  -2.675  0.00885 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4748 on 92 degrees of freedom
## Multiple R-squared:  0.9537, Adjusted R-squared:  0.9522 
## F-statistic: 631.6 on 3 and 92 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb201"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#anova(fit2)</span></span></code></pre></div>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-127-1.png" width="576" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb202"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit2</span> <span class="op">|&gt;</span> <span class="fu">augment</span><span class="op">(</span><span class="va">brain.data</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">.std.resid</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 3 × 11
##   SPECIES     BRAIN  BODY GESTATION LITTER .fitted .resid   .hat .sigma .cooksd
##   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 Human being  1300    65       270      1    5.60  1.57  0.0225  0.447  0.0647
## 2 Dolphin      1600   160       360      1    6.23  1.14  0.0312  0.462  0.0483
## 3 Tapir         250   230       390      1    6.48 -0.954 0.0342  0.466  0.0370
## # ℹ 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<p>The biggest standardised residual is now case 24 (Human) who have a larger brain than predicted by the model.</p>
<div class="sourceCode" id="cb204"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit2</span> <span class="op">|&gt;</span> <span class="fu">augment</span><span class="op">(</span><span class="va">brain.data</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="va">.hat</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">6</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 6 × 11
##   SPECIES    BRAIN   BODY GESTATION LITTER .fitted  .resid   .hat .sigma .cooksd
##   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;     &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 Quokka     17.5    3.5         26    1     2.94  -0.0747 0.259   0.477 2.93e-3
## 2 Domestic… 180    190          115    8     5.21  -0.0176 0.146   0.477 6.89e-5
## 3 Gentle l…   7.8    0.22       145    2     1.85   0.205  0.116   0.477 6.93e-3
## 4 Nutria     23      5          132    5.5   3.29  -0.157  0.114   0.477 3.95e-3
## 5 Hyrax      20.5    3.8        225    2.4   3.61  -0.594  0.100   0.473 4.85e-2
## 6 Hampster…   1.12   0.13        16    6.3   0.270 -0.156  0.0711  0.477 2.23e-3
## # ℹ 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb206"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit2</span> <span class="op">|&gt;</span> <span class="fu">augment</span><span class="op">(</span><span class="va">brain.data</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="va">.cooksd</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 3 × 11
##   SPECIES      BRAIN  BODY GESTATION LITTER .fitted .resid   .hat .sigma .cooksd
##   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 Hippopotam…  590   1.4e3       240    1      7.31 -0.931 0.0645  0.467  0.0709
## 2 Human being 1300   6.5e1       270    1      5.60  1.57  0.0225  0.447  0.0647
## 3 Hyrax         20.5 3.8e0       225    2.4    3.61 -0.594 0.100   0.473  0.0485
## # ℹ 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<p>Highest leverage is case 1 (quokka), but it doesn’t have high influence (this also goes for all cases with <span class="math inline">\(h_{ii} &gt; 0.083 = 2p/n\)</span>, where average <span class="math inline">\(h_{ii} = p/n\)</span>, except for case 73 (hyrax) which has longer gestation).</p>
<p>The residual distribution shows some skeweness, but is closer to normal than before.</p>
<p>The residual vs fit plot shows some evidence of non-constant variance. Perhaps some other transformation would be better?</p>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-130-1.png" width="576" style="display: block; margin: auto;"></div>
<!-- %plot(log(GESTATION), log(LITTER)) -->
<!-- %text(log(GESTATION), log(LITTER),labels = SPECIES, cex= 0.7, offset = 10) -->
<!-- % -->
<!-- % # large leverage -->
<!-- % head(brain.data[sort(influence(fit2)$hat, decreasing = TRUE, index.return = TRUE)$ix, 1]) -->
<!-- % -->
<!-- % # large std residual -->
<!-- % head(brain.data[sort(abs(stdres(fit2)), decreasing = TRUE, index.return = TRUE)$ix, 1]) -->
<!-- %``` -->
<!-- To make these plots in minitab use the storage option for standardised residuals, Cook's dist and leverages. -->
<p>To answer the original question, clearly gestation time and litter size are important predictors of brain size in the presence of body size.</p>
</div>
<div id="example-2-rat-data" class="section level3" number="6.8.2">
<h3>
<span class="header-section-number">6.8.2</span> Example 2: Rat data<a class="anchor" aria-label="anchor" href="#example-2-rat-data"><i class="fas fa-link"></i></a>
</h3>
<p>Example from <span class="citation">Weisberg (<a href="references.html#ref-weisberg2005applied">2005</a>)</span>.</p>
<p>Experiment to investigate amount of drug present in liver of rat.</p>
<ul>
<li><p>BodyWt = body weight of the rat</p></li>
<li><p>LiverWt = measured after sacrifice</p></li>
<li><p>Dose = dose given, proportional to body weight</p></li>
<li><p>EndDose = dose of drug recovered after sacrifice of the animal</p></li>
</ul>
<p>Experimantal hypothesis: no relationship between EndDose and 3 predictors.</p>
<div class="sourceCode" id="cb208"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rats.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"data/rat.txt"</span>, header <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">rats.data</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">EndDose</span>, <span class="va">BodyWt</span>, <span class="va">LiverWt</span>, <span class="va">Dose</span><span class="op">)</span><span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-131-1.png" width="576" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb209"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#library(car)</span></span>
<span><span class="co">#library(MASS)</span></span>
<span><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">EndDose</span> <span class="op">~</span> <span class="va">BodyWt</span> <span class="op">+</span>  <span class="va">LiverWt</span> <span class="op">+</span> <span class="va">Dose</span>, data <span class="op">=</span> <span class="va">rats.data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = EndDose ~ BodyWt + LiverWt + Dose, data = rats.data)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.100557 -0.063233  0.007131  0.045971  0.134691 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  0.265922   0.194585   1.367   0.1919  
## BodyWt      -0.021246   0.007974  -2.664   0.0177 *
## LiverWt      0.014298   0.017217   0.830   0.4193  
## Dose         4.178111   1.522625   2.744   0.0151 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.07729 on 15 degrees of freedom
## Multiple R-squared:  0.3639, Adjusted R-squared:  0.2367 
## F-statistic:  2.86 on 3 and 15 DF,  p-value: 0.07197</code></pre>
<div class="sourceCode" id="cb211"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#anova(fit1)</span></span></code></pre></div>
<p>It appears as if a combination of bodyweight and dose are relevant to EndDose. However, they are not individually related to EndDose even though <span class="math inline">\(X_1 \propto X_3\)</span></p>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-133-1.png" width="576" style="display: block; margin: auto;"></div>
<p>Case 3 has large influence (see Cook’s distance plot).</p>
<p>Case 3 is an unusual combination of dose and bodyweight.</p>
<div class="sourceCode" id="cb212"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">|&gt;</span>  <span class="fu">augment</span><span class="op">(</span><span class="va">rats.data</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="va">.hat</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 6 × 10
##   BodyWt LiverWt  Dose EndDose .fitted  .resid  .hat .sigma .cooksd .std.resid
##    &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;
## 1    190     9    1       0.56   0.536  0.0241 0.851 0.0782 0.930        0.807
## 2    200     7.2  1       0.23   0.298 -0.0677 0.392 0.0766 0.203       -1.12 
## 3    149     5.2  0.75    0.21   0.308 -0.0982 0.316 0.0734 0.273       -1.54 
## 4    195    10    0.98    0.41   0.360  0.0496 0.254 0.0785 0.0469       0.743
## 5    186     6.8  0.94    0.28   0.339 -0.0588 0.217 0.0780 0.0510      -0.859
## 6    146     7.3  0.73    0.3    0.318 -0.0184 0.195 0.0798 0.00425     -0.265</code></pre>
<p>A rat was given a dose that was too high for his bodyweight.</p>
<div class="sourceCode" id="cb214"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/car/man/avPlots.html">avPlots</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-135-1.png" width="672" style="display: block; margin: auto;"></div>
<p>Redo the analysis with case 3 removed:</p>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-136-1.png" width="576" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb215"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">EndDose</span> <span class="op">~</span> <span class="va">BodyWt</span> <span class="op">+</span>  <span class="va">LiverWt</span> <span class="op">+</span> <span class="va">Dose</span>, data <span class="op">=</span> <span class="va">rats.data</span><span class="op">[</span><span class="op">-</span><span class="fl">3</span>,<span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = EndDose ~ BodyWt + LiverWt + Dose, data = rats.data[-3, 
##     ])
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.102154 -0.056486  0.002838  0.046519  0.137059 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.311427   0.205094   1.518    0.151
## BodyWt      -0.007783   0.018717  -0.416    0.684
## LiverWt      0.008989   0.018659   0.482    0.637
## Dose         1.484877   3.713064   0.400    0.695
## 
## Residual standard error: 0.07825 on 14 degrees of freedom
## Multiple R-squared:  0.02106,    Adjusted R-squared:  -0.1887 
## F-statistic: 0.1004 on 3 and 14 DF,  p-value: 0.9585</code></pre>
<div class="sourceCode" id="cb217"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#anova(fit1)</span></span></code></pre></div>
<p>Experimental hypothesis is validated as all coefficients have large P-values.</p>
<div class="inline-figure"><img src="ST303-Lecture-Notes_files/figure-html/unnamed-chunk-138-1.png" width="576" style="display: block; margin: auto;"></div>
<div id="should-unusual-data-be-discarded" class="section level4" number="6.8.2.1">
<h4>
<span class="header-section-number">6.8.2.1</span> Should Unusual Data Be Discarded?<a class="anchor" aria-label="anchor" href="#should-unusual-data-be-discarded"><i class="fas fa-link"></i></a>
</h4>
<p>Although problematic data should not be ignored, they also should not be deleted automatically. It is important to investigate why an observation is unusual.</p>
<p>Truly bad data (e.g.rats) can be corrected or thrown away. When a discrepant data-point is correct, we may be able to understand why the observation is unusual.</p>
<p>For Species Brain data, it makes sense that humans enjoy brain size not accounted for by the other variables. In a case like this, we may choose to deal separately with an outlying observation.</p>
<p>Outliers or influential data may motivate model respecification e.g. the introduction of additional explanatory variables.</p>
<p>However, we must be careful to avoid overfitting the data i.e. permitting a small portion of the data to determine the form of the model.</p>
<p>A more extensive discussion can be found in <span class="citation">Fox (<a href="references.html#ref-fox2016applied">2016</a>)</span> Chapter 11.7, pg 288-289.</p>
<!-- #### Demonstrate effect of omiting cases on regression line -->
<!-- Cigarette data from \@ref(cigarette). Select a point to remove and refit the model.  -->
<!-- <https://rstudioserver.maths.nuim.ie:3838/churley/cig.Rmd> -->

</div>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="model-comparisons-and-testing-for-lack-of-fit.html"><span class="header-section-number">5</span> Model comparisons and testing for lack of fit</a></div>
<div class="next"><a href="special-cases-of-multiple-regression.html"><span class="header-section-number">7</span> Special cases of multiple regression</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#diagnostic-methods-in-more-details"><span class="header-section-number">6</span> Diagnostic methods (in more details)</a></li>
<li><a class="nav-link" href="#model-assumptions"><span class="header-section-number">6.1</span> Model assumptions</a></li>
<li><a class="nav-link" href="#residuals-1"><span class="header-section-number">6.2</span> Residuals</a></li>
<li>
<a class="nav-link" href="#leverage-values"><span class="header-section-number">6.3</span> Leverage values</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#properties-of-h_ii"><span class="header-section-number">6.3.1</span> Properties of \(h_{ii}\):</a></li></ul>
</li>
<li><a class="nav-link" href="#standardised-residuals"><span class="header-section-number">6.4</span> Standardised residuals</a></li>
<li><a class="nav-link" href="#leave-one-out-methods"><span class="header-section-number">6.5</span> Leave-one-out methods</a></li>
<li><a class="nav-link" href="#other-influence-measures"><span class="header-section-number">6.6</span> Other influence measures</a></li>
<li><a class="nav-link" href="#testing-outliers"><span class="header-section-number">6.7</span> Testing outliers</a></li>
<li>
<a class="nav-link" href="#diagnostics-examples-two-case-studies"><span class="header-section-number">6.8</span> Diagnostics examples (two case studies)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#example-1-brain-size-versus-body-gestation-period-and-litter"><span class="header-section-number">6.8.1</span> Example 1: Brain size versus body gestation period and litter</a></li>
<li><a class="nav-link" href="#example-2-rat-data"><span class="header-section-number">6.8.2</span> Example 2: Rat data</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Linear Models Lecture Notes</strong>" was written by Katarina Domijan. It was last built on 2025-12-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
